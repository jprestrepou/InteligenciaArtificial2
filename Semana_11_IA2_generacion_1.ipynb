{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7agBFkYeKcM",
        "outputId": "dea75e9b-e926-46ae-f8f4-d5f16fa13bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 2.3971 - accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3935 - accuracy: 0.2000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3899 - accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.3863 - accuracy: 0.2000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3826 - accuracy: 0.2000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3789 - accuracy: 0.2000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3751 - accuracy: 0.2000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3712 - accuracy: 0.2000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3672 - accuracy: 0.2000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3631 - accuracy: 0.2000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.3588 - accuracy: 0.2000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.3544 - accuracy: 0.2000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3497 - accuracy: 0.2000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3448 - accuracy: 0.2000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3397 - accuracy: 0.2000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3344 - accuracy: 0.2000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3288 - accuracy: 0.2000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3228 - accuracy: 0.2000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3166 - accuracy: 0.2000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3100 - accuracy: 0.2000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3030 - accuracy: 0.2000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2956 - accuracy: 0.2000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2877 - accuracy: 0.2000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2794 - accuracy: 0.2000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2705 - accuracy: 0.2000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2611 - accuracy: 0.2000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2511 - accuracy: 0.2000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2404 - accuracy: 0.2000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2290 - accuracy: 0.2000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2169 - accuracy: 0.2000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2039 - accuracy: 0.2000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1900 - accuracy: 0.2000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1752 - accuracy: 0.2000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1594 - accuracy: 0.2000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1425 - accuracy: 0.2000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1245 - accuracy: 0.2000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1053 - accuracy: 0.2000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0849 - accuracy: 0.2000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0631 - accuracy: 0.2000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0401 - accuracy: 0.2000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0158 - accuracy: 0.2000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9903 - accuracy: 0.2000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9636 - accuracy: 0.2000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9360 - accuracy: 0.2000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9075 - accuracy: 0.2000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8784 - accuracy: 0.2000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8491 - accuracy: 0.2000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8199 - accuracy: 0.2000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7911 - accuracy: 0.2000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7632 - accuracy: 0.2000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7364 - accuracy: 0.2000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7112 - accuracy: 0.2000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6875 - accuracy: 0.2000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6658 - accuracy: 0.2000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6459 - accuracy: 0.2000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6279 - accuracy: 0.2000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6116 - accuracy: 0.2000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5967 - accuracy: 0.2000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5830 - accuracy: 0.2000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5700 - accuracy: 0.2000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5575 - accuracy: 0.2000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5450 - accuracy: 0.2000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.5325 - accuracy: 0.2000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5199 - accuracy: 0.2000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.5072 - accuracy: 0.2000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4944 - accuracy: 0.2000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4817 - accuracy: 0.2000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4691 - accuracy: 0.2000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4567 - accuracy: 0.2000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4445 - accuracy: 0.2000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4325 - accuracy: 0.2000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4206 - accuracy: 0.2000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4087 - accuracy: 0.2000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3968 - accuracy: 0.2000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3848 - accuracy: 0.2000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3727 - accuracy: 0.4000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3605 - accuracy: 0.4000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3483 - accuracy: 0.4000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3360 - accuracy: 0.6000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.3238 - accuracy: 0.6000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3117 - accuracy: 0.6000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2996 - accuracy: 0.6000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2876 - accuracy: 0.6000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.2756 - accuracy: 0.6000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2635 - accuracy: 0.6000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2514 - accuracy: 0.6000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.2392 - accuracy: 0.6000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2269 - accuracy: 0.6000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2145 - accuracy: 0.6000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2021 - accuracy: 0.6000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1896 - accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1772 - accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1647 - accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1523 - accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1400 - accuracy: 0.6000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1276 - accuracy: 0.8000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.1153 - accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1029 - accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0905 - accuracy: 0.8000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0781 - accuracy: 0.8000\n",
            "1/1 [==============================] - 1s 643ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "El gato juega juega juega juega juega en en en en en juega juega juega juega juega en en en en en\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Datos de entrenamiento\n",
        "text = \"El gato está sobre la mesa. El perro juega en el jardín.\"\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "sequences = tokenizer.texts_to_sequences([text])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Preparación de los datos\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:-1]\n",
        "y = sequences[1:]\n",
        "X = pad_sequences([X], maxlen=5)\n",
        "y = pad_sequences([y], maxlen=5)\n",
        "\n",
        "# Convertir las etiquetas a codificación one-hot\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# Crear el modelo\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=5))\n",
        "model.add(LSTM(50,  return_sequences=True))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Generación de texto\n",
        "seed_text = \"El gato\"\n",
        "for _ in range(20):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=5)\n",
        "    y_pred = model.predict(encoded)\n",
        "    next_word_index = np.argmax(y_pred[0], axis=-1)[0].item()\n",
        "    next_word = tokenizer.index_word[next_word_index]\n",
        "    seed_text += \" \" + next_word\n",
        "\n",
        "print(seed_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Datos de entrenamiento (texto más largo)\n",
        "text = \"\"\"\n",
        "          Había una vez, en un bosque encantado, una comunidad de animales que\n",
        "          vivía en armonía. Los bosques estaban llenos de árboles altos y\n",
        "          frondosos, y los rayos del sol se filtraban a través de las hojas,\n",
        "          creando un mágico juego de luces y sombras.\n",
        "          Entre los habitantes del bosque, se encontraban el zorro astuto\n",
        "          llamado Zorro, el búho sabio llamado Sabio, y el conejo curioso\n",
        "          llamado Curioso. Cada día, se reunían alrededor del gran roble\n",
        "          en el centro del bosque para compartir historias y sabiduría.\n",
        "          Un día, una extraña criatura llegó al bosque. Era un armadillo\n",
        "          llamado Armadix. Se movía torpemente con su caparazón y parecía\n",
        "          perdido. Los otros animales se acercaron a él con curiosidad.\n",
        "          Zorro, siempre astuto, decidió ayudar a Armadix a encontrar su\n",
        "          camino de regreso a casa. Sabio, el búho, usó su conocimiento\n",
        "          para trazar un mapa y Curioso, el conejo, se ofreció a guiarlo.\n",
        "          A medida que avanzaban a través del bosque, Armadix comenzó a\n",
        "          hablar sobre su tierra natal, un lejano lugar lleno de desafíos\n",
        "          y peligros. Los otros animales escucharon atentamente y aprendieron\n",
        "          mucho sobre la vida más allá del bosque encantado.\n",
        "          Después de un largo viaje, finalmente llegaron a la casa de Armadix.\n",
        "          El pequeño armadillo estaba agradecido y les prometió que siempre recordaría\n",
        "          la amabilidad de los animales del bosque. Armadix les contó sobre un hermoso\n",
        "          jardín secreto que se escondía en el bosque y los invitó a visitarlo cuando quisieran.\n",
        "          El bosque encantado seguía siendo un lugar mágico, pero ahora había un\n",
        "          vínculo aún más fuerte entre los animales. Aprendieron que la amistad y\n",
        "          la colaboración podían superar cualquier desafío, y que la curiosidad\n",
        "          por el mundo exterior solo los había unido más.\n",
        "          Y así, la comunidad de animales continuó viviendo en armonía, compartiendo\n",
        "          historias y sabiduría bajo la sombra del gran roble en el Bosque Encantado.\n",
        "    \"\"\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "sequences = tokenizer.texts_to_sequences([text])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Preparación de los datos\n",
        "sequences = np.array(sequences)\n",
        "sequence_length = 5  # Longitud de las secuencias\n",
        "X, y = [], []\n",
        "for i in range(0, len(sequences) - sequence_length):\n",
        "    X.append(sequences[i:i + sequence_length])\n",
        "    y.append(sequences[i + sequence_length])\n",
        "X = pad_sequences(X, maxlen=sequence_length)\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# Crear el modelo\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=sequence_length))\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(sequence_length, vocab_size)))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Generación de texto\n",
        "seed_text = \"El gato está sobre la mesa. El perro esta en la casa de mis\"\n",
        "for _ in range(20):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    if len(encoded) < sequence_length:\n",
        "        break\n",
        "    encoded = pad_sequences([encoded[-sequence_length:]], maxlen=sequence_length)\n",
        "    y_pred = model.predict(encoded)\n",
        "    next_word_index = np.argmax(y_pred, axis=-1)[0]\n",
        "    next_word = tokenizer.index_word[next_word_index]\n",
        "    seed_text += \" \" + next_word\n",
        "\n",
        "print(seed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rEGmh4yEr1M",
        "outputId": "8363f1f6-21b6-4104-a5df-c4a9217e0502"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 15s 21ms/step - loss: 5.0360 - accuracy: 0.0099\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.0274 - accuracy: 0.0364\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 5.0071 - accuracy: 0.0497\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.9090 - accuracy: 0.0497\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.7425 - accuracy: 0.0497\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.6856 - accuracy: 0.0497\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.6562 - accuracy: 0.0497\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4.6407 - accuracy: 0.0497\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.6361 - accuracy: 0.0497\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 4.6312 - accuracy: 0.0497\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 4.6282 - accuracy: 0.0497\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.6222 - accuracy: 0.0497\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 4.6123 - accuracy: 0.0497\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 4.5743 - accuracy: 0.0497\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 4.5053 - accuracy: 0.0497\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 4.4622 - accuracy: 0.0497\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 4.4136 - accuracy: 0.0497\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.3864 - accuracy: 0.0464\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 4.3567 - accuracy: 0.0464\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.3326 - accuracy: 0.0464\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 4.3119 - accuracy: 0.0464\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.2894 - accuracy: 0.0464\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 4.2595 - accuracy: 0.0464\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.2406 - accuracy: 0.0464\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.2134 - accuracy: 0.0530\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1943 - accuracy: 0.0497\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.1689 - accuracy: 0.0530\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.1507 - accuracy: 0.0530\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1290 - accuracy: 0.0563\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 4.1099 - accuracy: 0.0530\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.0787 - accuracy: 0.0596\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0671 - accuracy: 0.0497\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0409 - accuracy: 0.0629\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0149 - accuracy: 0.0629\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.9899 - accuracy: 0.0762\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.9532 - accuracy: 0.0695\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.9373 - accuracy: 0.0795\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.9144 - accuracy: 0.0762\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 3.8988 - accuracy: 0.0762\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 3.8817 - accuracy: 0.0795\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 3.8514 - accuracy: 0.0828\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.8233 - accuracy: 0.0828\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 3.8186 - accuracy: 0.0861\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 3.8035 - accuracy: 0.0894\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 3.7815 - accuracy: 0.0828\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 3.7598 - accuracy: 0.0894\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 3.7371 - accuracy: 0.0861\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 3.7162 - accuracy: 0.0927\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 3.7096 - accuracy: 0.0993\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 3.6968 - accuracy: 0.0861\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 3.6914 - accuracy: 0.0927\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6825 - accuracy: 0.0828\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6693 - accuracy: 0.0894\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.6580 - accuracy: 0.1126\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.6478 - accuracy: 0.0960\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6333 - accuracy: 0.1026\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6171 - accuracy: 0.0993\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.6063 - accuracy: 0.0927\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.5857 - accuracy: 0.1060\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5656 - accuracy: 0.1060\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.5585 - accuracy: 0.0993\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5416 - accuracy: 0.1126\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.5395 - accuracy: 0.1060\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5174 - accuracy: 0.0960\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.5296 - accuracy: 0.0993\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.5071 - accuracy: 0.0960\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.4935 - accuracy: 0.1060\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.4968 - accuracy: 0.0927\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5099 - accuracy: 0.1026\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.4760 - accuracy: 0.1126\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.4671 - accuracy: 0.0993\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.4458 - accuracy: 0.0960\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.4569 - accuracy: 0.1093\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.4360 - accuracy: 0.1159\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.4241 - accuracy: 0.1060\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.4157 - accuracy: 0.1225\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.4070 - accuracy: 0.1159\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.4118 - accuracy: 0.1192\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.3988 - accuracy: 0.1060\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.3714 - accuracy: 0.1159\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.3525 - accuracy: 0.1225\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.3488 - accuracy: 0.1225\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.3494 - accuracy: 0.1093\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.3342 - accuracy: 0.1225\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.3124 - accuracy: 0.1424\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 3.3081 - accuracy: 0.1424\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 3.2979 - accuracy: 0.1358\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 3.3034 - accuracy: 0.1325\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.2979 - accuracy: 0.1225\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.2758 - accuracy: 0.1424\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 3.2715 - accuracy: 0.1424\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 3.2873 - accuracy: 0.1325\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 3.2610 - accuracy: 0.1391\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 3.2278 - accuracy: 0.1589\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 3.2234 - accuracy: 0.1623\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.2100 - accuracy: 0.1656\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.1974 - accuracy: 0.1589\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1879 - accuracy: 0.1689\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.1782 - accuracy: 0.1523\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1716 - accuracy: 0.1424\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "El gato está sobre la mesa. El perro esta en la casa de mis un comunidad siempre curiosidad bosque bosque y del historias su su su su una su su del el bosque su\n"
          ]
        }
      ]
    }
  ]
}